{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6e8a721-4034-420e-97bb-9b7ae92f69c4",
   "metadata": {},
   "source": [
    "# Chains in LangChain: What & Why\n",
    "\n",
    "## What are Chains in LangChain?\n",
    "\n",
    "**Chains** in LangChain are sequences of steps (often involving language models and other components) that are linked together to perform complex tasks. Each step in a chain can take input, process it (with an LLM, tool, or other logic), and pass its output to the next step. Chains allow you to build sophisticated workflows beyond single-call LLM interactions.\n",
    "\n",
    "**Types of Chains:**\n",
    "- **Simple Chains:** Pass input to a prompt and get the LLM’s output.\n",
    "- **Sequential Chains:** Multiple steps executed one after another, each using the previous output.\n",
    "- **Router Chains:** Dynamically route input to different chains/components based on logic.\n",
    "- **Custom Chains:** Any logic that involves LLMs and other tools in a specific order.\n",
    "\n",
    "## Why Use Chains?\n",
    "\n",
    "### 1. **Modularity & Composition**\n",
    "   - Break down large, complex tasks into manageable, reusable steps.\n",
    "   - Combine different models, prompts, or tools in a flexible way.\n",
    "\n",
    "### 2. **Automation**\n",
    "   - Automate multi-step processes (e.g. extract info, summarize, then call an API).\n",
    "   - Build pipelines that would be tedious or error-prone to manage manually.\n",
    "\n",
    "### 3. **Reliability**\n",
    "   - Enforce structure and order in interactions.\n",
    "   - Handle conditional logic, retries, or error handling programmatically.\n",
    "\n",
    "### 4. **Scalability**\n",
    "   - Easily add, remove, or modify steps as requirements change.\n",
    "   - Share and reuse chains across projects.\n",
    "\n",
    "### 5. **Integrating Tools**\n",
    "   - Combine LLMs with external APIs, databases, calculations, or other tools in a single workflow.\n",
    "\n",
    "## Example: Simple Sequential Chain\n",
    "\n",
    "```python\n",
    "from langchain.chains import SimpleSequentialChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "# Step 1: Summarize text\n",
    "prompt1 = PromptTemplate(input_variables=[\"text\"], template=\"Summarize: {text}\")\n",
    "chain1 = LLMChain(llm=llm, prompt=prompt1)\n",
    "\n",
    "# Step 2: Extract keywords from summary\n",
    "prompt2 = PromptTemplate(input_variables=[\"text\"], template=\"Extract keywords: {text}\")\n",
    "chain2 = LLMChain(llm=llm, prompt=prompt2)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1, chain2])\n",
    "result = overall_chain.run(\"LangChain is a framework for LLM applications.\")\n",
    "```\n",
    "\n",
    "## Summary Table\n",
    "\n",
    "| Feature                         | Benefit                                 |\n",
    "|----------------------------------|-----------------------------------------|\n",
    "| **Modularity**                  | Reusable, composable steps              |\n",
    "| **Automation**                  | Multi-step workflows                    |\n",
    "| **Reliability**                 | Predictable, structured processes       |\n",
    "| **Flexibility**                 | Mix LLMs, tools, logic                  |\n",
    "| **Scalability**                 | Easy to expand or refactor workflows    |\n",
    "\n",
    "---\n",
    "\n",
    "**In Short:**  \n",
    "Chains in LangChain help you build complex, reliable, and modular workflows by linking LLM calls, tools, and logic together—unlocking the full power of automation with language models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dfb9cb-b489-4e63-a092-fb86eb52f26a",
   "metadata": {},
   "source": [
    "# Sequential Chain in LangChain\n",
    "\n",
    "### What is a Sequential Chain?\n",
    "\n",
    "A **Sequential Chain** in LangChain is a workflow where multiple steps (chains, LLM calls, or tools) are executed one after another. The output of each step is passed as input to the next step, allowing you to build multi-step pipelines for complex tasks.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Chaining:** Connect several chains or tools in a linear sequence.\n",
    "- **Data Passing:** Output from one step is input to the next.\n",
    "- **Modularity:** Each step can be an LLM chain, a prompt, or a custom function.\n",
    "\n",
    "\n",
    "### Why Use Sequential Chains?\n",
    "\n",
    "- **Automation:** Automate multi-step processes (e.g., summarize → extract keywords → format as JSON).\n",
    "- **Clarity:** Break down complex logic into manageable, reusable steps.\n",
    "- **Flexibility:** Mix and match different LLMs, prompts, and tools in a workflow.\n",
    "\n",
    "\n",
    "### Example: Simple Sequential Chain\n",
    "\n",
    "```python\n",
    "from langchain.chains import SimpleSequentialChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "# Step 1: Summarize text\n",
    "prompt1 = PromptTemplate(input_variables=[\"text\"], template=\"Summarize: {text}\")\n",
    "chain1 = LLMChain(llm=llm, prompt=prompt1)\n",
    "\n",
    "# Step 2: Extract keywords from the summary\n",
    "prompt2 = PromptTemplate(input_variables=[\"text\"], template=\"Extract keywords: {text}\")\n",
    "chain2 = LLMChain(llm=llm, prompt=prompt2)\n",
    "\n",
    "# Compose them in a sequential chain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1, chain2])\n",
    "\n",
    "result = overall_chain.run(\"LangChain is a framework for building applications powered by LLMs.\")\n",
    "print(result)\n",
    "```\n",
    "\n",
    "### Types of Sequential Chains in LangChain\n",
    "\n",
    "- **SimpleSequentialChain:** Passes only a string output from one chain to the next.\n",
    "- **SequentialChain:** Handles more complex input/output with multiple named variables for each step.\n",
    "\n",
    "\n",
    "### Example: Advanced SequentialChain\n",
    "\n",
    "```python\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains=[chain1, chain2],\n",
    "    input_variables=[\"text\"],\n",
    "    output_variables=[\"summary\", \"keywords\"],\n",
    "    verbose=True,\n",
    ")\n",
    "```\n",
    "- This allows for more complex data passing and multiple outputs.\n",
    "\n",
    "\n",
    "### When to Use Sequential Chains?\n",
    "\n",
    "- When your workflow requires multiple, dependent LLM or tool calls.\n",
    "- When each step builds on the previous one's output.\n",
    "- For readable, maintainable, and reusable pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cac393-6414-400c-83cf-5afb472981d2",
   "metadata": {},
   "source": [
    "# Parallel Chain in LangChain\n",
    "\n",
    "### What is a Parallel Chain?\n",
    "\n",
    "A **Parallel Chain** in LangChain is a chain that allows you to execute multiple sub-chains or steps at the same time (in parallel), rather than one after the other. This is useful when you want to process the same input in different ways or perform multiple independent tasks simultaneously, then gather their outputs.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Parallel Execution:** Runs multiple chains or tools at once.\n",
    "- **Same Input:** All sub-chains receive the same input at the start.\n",
    "- **Aggregated Output:** Collects the outputs from all sub-chains into a single result (often a dictionary, with keys for each sub-chain).\n",
    "- **Efficiency:** Can be faster than sequential chains for independent tasks.\n",
    "\n",
    "\n",
    "### Why Use Parallel Chains?\n",
    "\n",
    "- **Efficiency:** Save time by running independent LLM calls or tools simultaneously.\n",
    "- **Versatility:** Useful for multi-task prompts (e.g., summarize + sentiment analysis) on the same input.\n",
    "- **Modularity:** Cleanly separate logic for different processing needs.\n",
    "\n",
    "### Example: ParallelChain Usage\n",
    "\n",
    "```python\n",
    "from langchain.chains import ParallelChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "# Define two tasks\n",
    "summary_prompt = PromptTemplate(input_variables=[\"text\"], template=\"Summarize: {text}\")\n",
    "keywords_prompt = PromptTemplate(input_variables=[\"text\"], template=\"Extract keywords: {text}\")\n",
    "\n",
    "summary_chain = LLMChain(llm=llm, prompt=summary_prompt)\n",
    "keywords_chain = LLMChain(llm=llm, prompt=keywords_prompt)\n",
    "\n",
    "# Compose them into a ParallelChain\n",
    "chain = ParallelChain(\n",
    "    chains={\n",
    "        \"summary\": summary_chain,\n",
    "        \"keywords\": keywords_chain,\n",
    "    },\n",
    "    input_variables=[\"text\"],\n",
    ")\n",
    "\n",
    "result = chain.run({\"text\": \"LangChain is an open-source framework for building with LLMs.\"})\n",
    "print(result)\n",
    "# Output example:\n",
    "# {'summary': 'LangChain is a framework for LLMs.', 'keywords': ['LangChain', 'LLMs', 'framework']}\n",
    "```\n",
    "\n",
    "### When to Use Parallel Chains?\n",
    "\n",
    "- When multiple independent outputs are needed from the same input.\n",
    "- When you want to maximize efficiency and speed for concurrent tasks.\n",
    "- For tasks like multi-label classification, simultaneous extraction, or multi-format output generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7882d751-4bbd-43c4-b687-570da0c659ff",
   "metadata": {},
   "source": [
    "# Conditional Chain in LangChain\n",
    "\n",
    "### What is a Conditional Chain?\n",
    "\n",
    "A **Conditional Chain** in LangChain is a chain that enables branching logic: it routes input data to different sub-chains or steps based on specified conditions or criteria. This is useful when you want your workflow to take different actions depending on the input—mimicking if/else statements or switch/case logic in traditional programming.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Dynamic Routing:** Directs input to different chains/functions based on conditions.\n",
    "- **Custom Logic:** Conditions can be based on input content, metadata, or processing results.\n",
    "- **Flexible Workflows:** Supports complex, non-linear automation scenarios.\n",
    "\n",
    "### Why Use Conditional Chains?\n",
    "\n",
    "- **Customization:** Tailor responses or actions to specific input types or values.\n",
    "- **Efficiency:** Avoid unnecessary computation by only running relevant sub-chains.\n",
    "- **Complex Logic:** Implement decision trees, command routing, or adaptive flows.\n",
    "\n",
    "### Example: ConditionalChain Usage\n",
    "\n",
    "```python\n",
    "from langchain.chains import ConditionalChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "\n",
    "# Define two possible sub-chains\n",
    "english_prompt = PromptTemplate(input_variables=[\"text\"], template=\"Summarize in English: {text}\")\n",
    "spanish_prompt = PromptTemplate(input_variables=[\"text\"], template=\"Resumir en español: {text}\")\n",
    "\n",
    "english_chain = LLMChain(llm=llm, prompt=english_prompt)\n",
    "spanish_chain = LLMChain(llm=llm, prompt=spanish_prompt)\n",
    "\n",
    "# Define a routing function\n",
    "def router(inputs):\n",
    "    if \"español\" in inputs[\"language\"]:\n",
    "        return \"spanish\"\n",
    "    return \"english\"\n",
    "\n",
    "# Build the ConditionalChain\n",
    "chain = ConditionalChain(\n",
    "    chains={\"english\": english_chain, \"spanish\": spanish_chain},\n",
    "    input_variables=[\"text\", \"language\"],\n",
    "    condition=router,\n",
    ")\n",
    "\n",
    "result = chain.run({\"text\": \"LangChain es útil.\", \"language\": \"español\"})\n",
    "print(result)\n",
    "# Output: (Summary in Spanish)\n",
    "```\n",
    "\n",
    "### When to Use Conditional Chains?\n",
    "\n",
    "- When your workflow must adapt based on user input or metadata.\n",
    "- For command interpreters, multi-language bots, or form processors.\n",
    "- When integrating LLMs with business logic or dynamic pipelines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
