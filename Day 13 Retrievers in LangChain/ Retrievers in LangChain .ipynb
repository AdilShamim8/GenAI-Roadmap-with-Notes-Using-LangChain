{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f06629bb-ace8-4b73-bf9e-58167dd8e310",
   "metadata": {},
   "source": [
    "# [Retrievers in LangChain](https://python.langchain.com/docs/integrations/retrievers/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462f4015-a6d8-44bb-ac60-8ceee65483d8",
   "metadata": {},
   "source": [
    "A retriever is a component in LangChain that fetches relevant documents from a\n",
    "data source in response to a userâ€™s query. <br>\n",
    "There are multiple types of retrievers <br>\n",
    "All retrievers in LangChain are runnables \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea856a31-c434-44ed-9b57-cac88d86edda",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle, Circle, Polygon\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.set_xlim(0, 12)\n",
    "ax.set_ylim(0, 6)\n",
    "ax.axis('off')  # turn off axes\n",
    "\n",
    "# Draw the Data Source (circle)\n",
    "data_source = Circle((1, 3), 1, color='yellow', ec='black')\n",
    "ax.add_patch(data_source)\n",
    "ax.text(1, 3, 'Data Source', ha='center', va='center')\n",
    "\n",
    "# Draw the Retriever (rectangle)\n",
    "retriever = Rectangle((4, 2.5), 2.5, 1, color='lightgreen', ec='black')\n",
    "ax.add_patch(retriever)\n",
    "ax.text(5.25, 3, 'Retriever', ha='center', va='center')\n",
    "\n",
    "# Draw the Document (stacked pages)\n",
    "# Since matplotlib doesn't have a stack of pages, we can draw multiple rectangles\n",
    "for i in range(3):\n",
    "    rect = Rectangle((8, 4 - i*0.2), 1.2, 0.2, color='pink', ec='black')\n",
    "    ax.add_patch(rect)\n",
    "ax.text(8.6, 3.85, 'Document', ha='center', va='center')\n",
    "\n",
    "# Draw the Query (diamond)\n",
    "query_coords = [(3.5, 2), (4.75, 1.2), (6, 2), (4.75, 2.8)]\n",
    "query = Polygon(query_coords, closed=True, color='lightblue', ec='black')\n",
    "ax.add_patch(query)\n",
    "ax.text(4.75, 1.9, 'Query', ha='center', va='center')\n",
    "\n",
    "# Draw arrows\n",
    "ax.annotate('', xy=(2, 3), xytext=(3.4, 3), arrowprops=dict(arrowstyle='->'))\n",
    "ax.annotate('', xy=(6.75, 3), xytext=(8, 3), arrowprops=dict(arrowstyle='->'))\n",
    "ax.annotate('', xy=(5.25, 2.5), xytext=(5.25, 2.2), arrowprops=dict(arrowstyle='->'))\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77602391-2fb9-4fce-95f1-0b9597ab85b0",
   "metadata": {},
   "source": [
    "## What are Retrievers?\n",
    "\n",
    "**Retrievers** in LangChain are components that take a user query and return the most relevant documents or pieces of information from a data source, typically for use as context in large language model (LLM) applications. Retrievers enable Retrieval-Augmented Generation (RAG) workflows, where an LLM is augmented with external knowledge at answer time.\n",
    "\n",
    "### Why Use Retrievers?\n",
    "\n",
    "- **Context Injection:** They inject relevant background information into LLM prompts, improving accuracy and relevance.\n",
    "- **Efficient Search:** They provide fast, scalable, and semantic search over large corpora.\n",
    "- **Flexible Sources:** They can retrieve from databases, vector stores, APIs, or custom backends.\n",
    "\n",
    "### How Do Retrievers Work?\n",
    "\n",
    "1. **Query Input:** The retriever receives a userâ€™s natural language query.\n",
    "2. **Transformation (optional):** The query may be rephrased, embedded, or otherwise transformed.\n",
    "3. **Search:** The retriever searches its underlying data source for relevant information (using keyword, embedding similarity, hybrid, or custom logic).\n",
    "4. **Return:** It returns a list of `Document` objects (or similar), ready for use in LLM prompts.\n",
    "\n",
    "### Types of Retrievers in LangChain\n",
    "\n",
    "#### 1. VectorStoreRetriever (Most common)\n",
    "- Uses a vector store (e.g., FAISS, Chroma, Pinecone) to find documents semantically similar to the query embedding.\n",
    "- Example:\n",
    "    ```python\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "    docs = retriever.get_relevant_documents(\"What is LangChain?\")\n",
    "    ```\n",
    "\n",
    "#### 2. SelfQueryRetriever\n",
    "- Uses an LLM to parse the query and generate structured search parameters, enabling more complex queries (like filters).\n",
    "\n",
    "#### 3. BM25Retriever & ElasticSearchRetriever\n",
    "- Use traditional keyword-based search (BM25, Elasticsearch) for lexical retrieval.\n",
    "\n",
    "#### 4. MultiQueryRetriever\n",
    "- Generates multiple variations of the user query (using an LLM) and retrieves documents for each, merging results for higher recall.\n",
    "\n",
    "#### 5. ParentDocumentRetriever\n",
    "- Retrieves parent documents based on matches in smaller child chunks, preserving full context.\n",
    "\n",
    "#### 6. ContextualCompressionRetriever\n",
    "- Combines retrieval with compression (summarization, re-ranking, etc.) for concise context delivery.\n",
    "\n",
    "#### 7. TimeWeightedVectorStoreRetriever\n",
    "- Adds recency or time-based weighting to retrieval (useful for chat/history).\n",
    "\n",
    "#### 8. EnsembleRetriever\n",
    "- Combines results from multiple retrievers (e.g., vector + keyword).\n",
    "\n",
    "\n",
    "#### Retriever vs. Vector Store\n",
    "\n",
    "- **Vector stores** store and index embeddings for fast similarity search.\n",
    "- **Retrievers** are the interface that queries the vector store (or other backend), applies logic/filters, and returns results.\n",
    "\n",
    "\n",
    "### Example: Basic Vector Store Retriever\n",
    "\n",
    "```python\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_texts([\"Doc1\", \"Doc2\", \"Doc3\"], OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "results = retriever.get_relevant_documents(\"What is Doc1 about?\")\n",
    "```\n",
    "### When to Use Retrievers\n",
    "\n",
    "- For RAG pipelines (supplying external knowledge to LLMs).\n",
    "- For document Q&A, semantic search, and chatbots.\n",
    "- When your data is too large to fit in a single LLM prompt.\n",
    "\n",
    "**Summary:**  \n",
    "Retrievers in LangChain are the crucial interface for searching and fetching relevant data to provide context to LLMs, powering accurate and scalable retrieval-augmented applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6766bcc4-ad4f-4973-a77a-110a784b9d50",
   "metadata": {},
   "source": [
    "# Types of Retrievers in LangChain\n",
    "\n",
    "LangChain offers a variety of retriever classes, each designed for different retrieval strategies and use cases. Below are the main types and a brief description of each:\n",
    "\n",
    "### 1. **VectorStoreRetriever**\n",
    "- **Description:** The most common retriever in LangChain, it queries a vector store (e.g., FAISS, Pinecone, Chroma) using embedding similarity to return documents most similar to the query.\n",
    "- **Use Case:** Semantic search, RAG pipelines, document Q&A.\n",
    "- **Example:**\n",
    "  ```python\n",
    "  retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "  docs = retriever.get_relevant_documents(\"What is LangChain?\")\n",
    "  ```\n",
    "\n",
    "### 2. **BM25Retriever**\n",
    "- **Description:** Uses the BM25 algorithm (a classic keyword-based search method) to find documents based on lexical similarity.\n",
    "- **Use Case:** When traditional keyword relevance is preferred or when embeddings are not suitable.\n",
    "\n",
    "## 3. **ElasticSearchRetriever / OpenSearchRetriever**\n",
    "- **Description:** Retrieves documents using Elasticsearch or OpenSearch, supporting both keyword and vector search.\n",
    "- **Use Case:** Enterprise search and hybrid search scenarios.\n",
    "\n",
    "### 4. **SelfQueryRetriever**\n",
    "- **Description:** Uses an LLM to parse the userâ€™s query and generate structured search parameters (e.g., filters, metadata constraints) for the underlying vector store.\n",
    "- **Use Case:** Advanced queries that require not just similarity, but also filtering or conditional logic.\n",
    "\n",
    "### 5. **MultiQueryRetriever**\n",
    "- **Description:** Uses an LLM to generate multiple diverse variations of the user query, retrieves documents for each, and merges the results for higher recall.\n",
    "- **Use Case:** Increasing coverage and robustness, especially for ambiguous or broad queries.\n",
    "\n",
    "\n",
    "### 6. **ParentDocumentRetriever**\n",
    "- **Description:** Retrieves parent documents based on matches found in smaller, embedded child chunks, ensuring more context is provided.\n",
    "- **Use Case:** When you want to return an entire section or document instead of just a small chunk.\n",
    "\n",
    "\n",
    "### 7. **ContextualCompressionRetriever**\n",
    "- **Description:** After retrieval, compresses or summarizes the documents (using an LLM or other compressor) before passing them to the LLM, providing concise context.\n",
    "- **Use Case:** When prompt size is limited or concise context is needed.\n",
    "\n",
    "\n",
    "### 8. **TimeWeightedVectorStoreRetriever**\n",
    "- **Description:** Adds recency or time-based weighting to the retrieval process, prioritizing more recent documents.\n",
    "- **Use Case:** Chatbots or applications where the most recent interactions are most relevant.\n",
    "\n",
    "## 9. **EnsembleRetriever**\n",
    "- **Description:** Combines the results of multiple retrievers (e.g., vector + keyword) for hybrid retrieval.\n",
    "- **Use Case:** Maximizing recall and precision by leveraging multiple retrieval strategies.\n",
    "\n",
    "### 10. **KNNRetriever**\n",
    "- **Description:** Performs k-nearest neighbors search on pre-computed document embeddings, sometimes outside a formal vector store.\n",
    "- **Use Case:** Lightweight or custom embedding stores.\n",
    "\n",
    "### 11. **TFIDFRetriever**\n",
    "- **Description:** Uses the TF-IDF algorithm for classic keyword relevance scoring.\n",
    "- **Use Case:** Simple, local, or prototyping scenarios.\n",
    "\n",
    "**Summary:**  \n",
    "LangChain provides a broad suite of retrievers, from semantic vector search to classic keyword and hybrid methods, enabling flexible and powerful retrieval-augmented LLM workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a446ed-e225-4998-bd0f-561c4151eec4",
   "metadata": {},
   "source": [
    "# Wikipedia Retriever\n",
    "A Wikipedia Retriever is a retriever that queries the Wikipedia API to fetch relevant content for\n",
    "a given query.\n",
    "### How It Works\n",
    "\n",
    "1. You give it a query (e.g., \"Albert Einstein\")  \n",
    "2. It sends the query to Wikipedia's API  \n",
    "3. It retrieves the **most relevant articles**  \n",
    "4. It returns them as LangChain **Document** objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aef4101-d894-4a22-b1b8-929052641db3",
   "metadata": {},
   "source": [
    "## What is the Wikipedia Retriever?\n",
    "\n",
    "The **Wikipedia Retriever** in LangChain is a retriever that fetches relevant information directly from Wikipedia in response to user queries. Instead of searching a local database or vector store, it issues real-time searches against Wikipedia's vast content, returning the most relevant page excerpts as `Document` objects. This is especially useful for augmenting LLMs with up-to-date, encyclopedic knowledge without building or maintaining your own corpus.\n",
    "\n",
    "### Features\n",
    "\n",
    "- **Live Retrieval:** Searches Wikipedia in real time for each query.\n",
    "- **Relevance Ranking:** Returns the most relevant articles or paragraphs based on the query.\n",
    "- **Plug-and-Play:** No need to create embeddings or vector stores for Wikipedia content.\n",
    "- **Language Support:** Can be configured to search Wikipedia in different languages.\n",
    "\n",
    "### Example Usage\n",
    "\n",
    "```python\n",
    "from langchain.retrievers import WikipediaRetriever\n",
    "\n",
    "# Initialize the retriever (English Wikipedia by default)\n",
    "retriever = WikipediaRetriever()\n",
    "\n",
    "# Retrieve documents relevant to your query\n",
    "docs = retriever.get_relevant_documents(\"What is LangChain?\")\n",
    "\n",
    "# Print the top result\n",
    "print(docs[0].page_content)\n",
    "```\n",
    "\n",
    "**Specifying Language:**\n",
    "```python\n",
    "retriever = WikipediaRetriever(lang=\"fr\")  # French Wikipedia\n",
    "docs = retriever.get_relevant_documents(\"Qu'est-ce que LangChain ?\")\n",
    "```\n",
    "### When to Use the Wikipedia Retriever\n",
    "\n",
    "- When you want to supplement your LLM with real-time, factual, and encyclopedic knowledge.\n",
    "- For RAG pipelines where up-to-date public information is needed.\n",
    "- If you want to avoid the setup or cost of maintaining a large local corpus for general knowledge queries.\n",
    "\n",
    "**Summary:**  \n",
    "The Wikipedia Retriever in LangChain allows you to retrieve and inject relevant Wikipedia content directly into your LLM pipelines, providing dynamic, up-to-date answers from one of the worldâ€™s largest knowledge bases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c52ffb-cc82-4bba-b4f5-2402beaa6c0a",
   "metadata": {},
   "source": [
    "# Vector Store Retriever\n",
    "A Vector Store Retriever in LangChain is the most common type of retriever that lets you\n",
    "search and fetch documents from a vector store based on semantic similarity using vector\n",
    "embeddings.\n",
    "### How It Works\n",
    "\n",
    "1. You store your **documents** in a **vector store** (like FAISS, Chroma, Weaviate)  \n",
    "2. Each document is converted into a **dense vector** using an **embedding** model  \n",
    "3. When the user enters a query:\n",
    "   - It's also turned into a **vector**\n",
    "   - The retriever compares the query **vector** with the stored vectors\n",
    "   - It retrieves the **top-k most similar ones**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c2637c-c1d1-4d50-b128-43f48aeab6a7",
   "metadata": {},
   "source": [
    "## What is a VectorStoreRetriever?\n",
    "\n",
    "A **VectorStoreRetriever** is a retriever in LangChain that uses a vector store (such as FAISS, Chroma, Pinecone, etc.) to find and return documents that are semantically similar to a given user query. It is the most common retriever used for semantic search and is the core retrieval mechanism in many RAG (Retrieval-Augmented Generation) pipelines.\n",
    "### How Does It Work?\n",
    "\n",
    "1. **Embedding Creation:** When a user submits a query, the query is converted into a vector embedding using the same embedding model used to store the documents.\n",
    "2. **Similarity Search:** The embedding is compared to all stored document embeddings in the vector store using a similarity metric (often cosine similarity).\n",
    "3. **Retrieval:** The top-k most similar documents are returned as relevant context for downstream tasks (like LLM prompts).\n",
    "\n",
    "### Why Use VectorStoreRetriever?\n",
    "\n",
    "- **Semantic Search:** Finds documents based on meaning, not just keywords.\n",
    "- **Scalable:** Efficiently handles large document collections.\n",
    "- **Plug-and-Play:** Easy to use with any supported vector store in LangChain.\n",
    "- **Customizable:** Supports filtering, metadata, and different similarity metrics.\n",
    "\n",
    "### Example Usage\n",
    "\n",
    "```python\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Step 1: Build a vector store with your documents\n",
    "texts = [\"LangChain is a framework for LLM apps.\", \"FAISS is a vector database.\", \"Retrievers inject context.\"]\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "# Step 2: Create a retriever from the vector store\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# Step 3: Retrieve relevant documents for a query\n",
    "docs = retriever.get_relevant_documents(\"What is LangChain?\")\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "```\n",
    "\n",
    "### Customization\n",
    "\n",
    "- **search_kwargs:**  \n",
    "  - `k`: Number of top documents to retrieve.\n",
    "  - `filter`: (if supported by the vector store) Metadata filter for more precise results.\n",
    "\n",
    "### When to Use VectorStoreRetriever\n",
    "\n",
    "- For semantic search over your document corpus.\n",
    "- In RAG pipelines to inject external context into LLM answers.\n",
    "- Whenever you need fast, meaningful retrieval from large text collections.\n",
    "\n",
    "**Summary:**  \n",
    "The VectorStoreRetriever is the standard retriever in LangChain for semantic search, retrieving the most relevant documents from a vector store to provide rich, contextual information for LLM-powered applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d686dbec-491f-4367-aa7a-c508dad227f1",
   "metadata": {},
   "source": [
    "# Maximal Marginal Relevance (MMR)\n",
    "> \"How can we pick results that are not only relevant to the query but also different from each other?\"  \n",
    "  \n",
    "MMR is an information retrieval algorithm designed to reduce redundancy in the retrieved results while maintaining high relevance to the query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a395c5e5-5f12-4471-b377-2c2ccd4ac653",
   "metadata": {},
   "source": [
    "### Why MMR Retriever?\n",
    "\n",
    "In **regular similarity search**, you may get documents that are:\n",
    "- All very similar to each other\n",
    "- Repeating the same info\n",
    "- Lacking diverse perspectives\n",
    "\n",
    "MMR Retriever avoids that by:\n",
    "- Picking the **most relevant document** first\n",
    "- Then picking the **next most relevant** and **least similar** to already selected docs\n",
    "- And so on...\n",
    "\n",
    "This helps especially in RAG pipelines where:\n",
    "- You want your context window to contain **diverse but still relevant information**\n",
    "- Especially useful when documents are semantically overlapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb4aca9-c0ea-48ae-aab9-a00bfc7e5d8c",
   "metadata": {},
   "source": [
    "| Doc ID | Content                                              |\n",
    "|--------|------------------------------------------------------|\n",
    "| D1     | \"Climate change is causing glaciers to melt rapidly in the Arctic region.\" |\n",
    "| D2     | \"Glaciers in the Arctic are melting at an alarming rate due to rising temperatures.\" |\n",
    "| D3     | \"Deforestation in the Amazon is accelerating global climate change.\" |\n",
    "| D4     | \"Climate change is increasing the frequency of wildfires in California.\" |\n",
    "| D5     | \"Rising sea levels due to climate change threaten coastal cities like Mumbai and New York.\" |\n",
    "\n",
    "### Top 3 results:\n",
    "1. **D1**: Arctic glaciers melting\n",
    "2. **D2**: Arctic glaciers melting\n",
    "3. **D5**: Rising sea levels in coastal cities\n",
    "\n",
    "### Top 3 results:\n",
    "1. **D1**: Arctic glaciers melting\n",
    "2. **D4**: Wildfires in California\n",
    "3. **D5**: Rising sea levels in coastal cities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b00f8d-e2f8-443b-a31c-05028d4bbf98",
   "metadata": {},
   "source": [
    "## What is Maximal Marginal Relevance (MMR)?\n",
    "\n",
    "**Maximal Marginal Relevance (MMR)** is an information retrieval technique that aims to maximize the relevance of retrieved items while minimizing redundancy. In the context of LangChain and LLM pipelines, MMR is used to select diverse and relevant chunks or documents from a vector store, ensuring the returned set covers different aspects of the user query rather than just repeating similar content.\n",
    "\n",
    "### Why Use MMR?\n",
    "\n",
    "- **Reduces Redundancy:** Prevents returning multiple nearly identical results that donâ€™t add value.\n",
    "- **Increases Diversity:** Ensures the retrieved set covers a wider range of topics or perspectives relevant to the query.\n",
    "- **Improves User Satisfaction:** Users get more comprehensive and less repetitive answers.\n",
    "\n",
    "### How Does MMR Work?\n",
    "\n",
    "MMR works by:\n",
    "1. Ranking candidate documents by their similarity to the query.\n",
    "2. Iteratively selecting documents that are both highly relevant to the query and maximally dissimilar from documents already selected.\n",
    "3. The process continues until `k` documents are selected.\n",
    "\n",
    "The selection is based on a trade-off parameter (Î», lambda) between relevance and diversity.\n",
    "\n",
    "### MMR in LangChain\n",
    "\n",
    "LangChain supports MMR in its retrievers, especially when using vector stores for semantic search.\n",
    "\n",
    "#### Enabling MMR in a VectorStoreRetriever\n",
    "\n",
    "```python\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Build your vector store\n",
    "texts = [\"Doc 1...\", \"Doc 2...\", \"Doc 3...\"]\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "# Use as a retriever with MMR enabled\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",                # Enable MMR\n",
    "    search_kwargs={\n",
    "        \"k\": 5,                       # Number of docs to return\n",
    "        \"fetch_k\": 20,                # Number of candidates to consider\n",
    "        \"lambda_mult\": 0.5            # Balance between relevance and diversity (0 = max diversity, 1 = max relevance)\n",
    "    }\n",
    ")\n",
    "\n",
    "results = retriever.get_relevant_documents(\"Explain maximal marginal relevance\")\n",
    "```\n",
    "\n",
    "- `k`: Final number of documents to return.\n",
    "- `fetch_k`: Number of top candidates to consider before MMR selection.\n",
    "- `lambda_mult`: Controls the relevance-diversity tradeoff.\n",
    "\n",
    "### When to Use MMR\n",
    "\n",
    "- When you want diverse, non-redundant results (e.g., Q&A, summarization, search).\n",
    "- If your corpus has many similar or overlapping documents.\n",
    "- In RAG, to provide a broader context for the LLM.\n",
    "\n",
    "**Summary:**  \n",
    "Maximal Marginal Relevance (MMR) in LangChain enables retrievers to return results that are both highly relevant and diverse, reducing redundancy and improving the quality of information provided to users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0bce28-43d7-4f1a-af47-d0dccaeae793",
   "metadata": {},
   "source": [
    "# Multi-Query Retriever\n",
    "\n",
    "> Sometimes a single query might not capture all the ways information is phrased in your documents.\n",
    "\n",
    "For example:\n",
    "\n",
    "**Query**: \"How can I stay healthy?\"\n",
    "\n",
    "Could mean:\n",
    "- What should I eat?\n",
    "- How often should I exercise?\n",
    "- How can I manage stress?\n",
    "\n",
    "A simple similarity search might **miss documents** that talk about those things but donâ€™t use the word \"healthy.\"\n",
    "> \"How can I stay healthy?\"\n",
    "1. **\"What are the best foods to maintain good health?\"**\n",
    "2. **\"How often should I exercise to stay fit?\"**\n",
    "3. **\"What lifestyle habits improve mental and physical wellness?\"**\n",
    "4. **\"How can I boost my immune system naturally?\"**\n",
    "\n",
    "### How it works\n",
    "1. Takes your original query\n",
    "2. Uses an LLM (e.g., GPT-3.5) to generate multiple semantically different versions of that query\n",
    "3. Performs retrieval for each sub-query\n",
    "4. Combines and deduplicates the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc64354-d7dc-4db9-b67b-ba0bf89e9586",
   "metadata": {},
   "source": [
    "### What is the MultiQueryRetriever?\n",
    "\n",
    "The **MultiQueryRetriever** is a retriever in LangChain that enhances recall by leveraging an LLM to generate multiple diverse reformulations of a userâ€™s query. For each query variant, it retrieves relevant documents from the underlying retriever (often a vector store or other retriever), then merges the results. This approach increases the chances of capturing all relevant information, especially for ambiguous or broad queries.\n",
    "\n",
    "### Why Use MultiQueryRetriever?\n",
    "\n",
    "- **Higher Recall:** By searching with several rephrased queries, you gather more potentially relevant documents.\n",
    "- **Diverse Coverage:** Captures different phrasings, synonyms, or aspects of the userâ€™s intent.\n",
    "- **Reduces Misses:** Helps when a single query might not match all relevant documents due to vocabulary mismatch or ambiguity.\n",
    "\n",
    "### How Does It Work?\n",
    "\n",
    "1. **LLM Reformulation:** The MultiQueryRetriever uses an LLM to generate several diverse variants of the original user query.\n",
    "2. **Parallel Retrieval:** Each variant is used to retrieve documents from the base retriever (e.g., a VectorStoreRetriever).\n",
    "3. **Result Merging:** Results from all queries are merged (deduplicated) and returned as the final set.\n",
    "\n",
    "### Example Usage\n",
    "\n",
    "```python\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Set up your base vector store retriever\n",
    "texts = [\"LangChain supports RAG.\", \"You can retrieve documents using embeddings.\", \"MultiQueryRetriever increases recall.\"]\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_texts(texts, embeddings)\n",
    "base_retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Set up the LLM\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# Create the MultiQueryRetriever\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=base_retriever,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "# Retrieve documents\n",
    "results = multi_query_retriever.get_relevant_documents(\"How does LangChain retrieve information?\")\n",
    "for doc in results:\n",
    "    print(doc.page_content)\n",
    "```\n",
    "\n",
    "### When to Use MultiQueryRetriever\n",
    "\n",
    "- When a single query might not surface all relevant documents.\n",
    "- For ambiguous, complex, or broad user questions.\n",
    "- For knowledge bases, RAG pipelines, or any application where maximizing relevant context is important.\n",
    "\n",
    "**Summary:**  \n",
    "The MultiQueryRetriever in LangChain uses an LLM to generate diverse query variants, improving recall and coverage when retrieving relevant documents for downstream LLM tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea8bdaf-dd2d-4ae4-a90f-93186f62c278",
   "metadata": {},
   "source": [
    "# Contextual Compression Retriever\n",
    "\n",
    "The **Contextual Compression Retriever** in LangChain is an advanced retriever that improves retrieval quality by **compressing documents** after retrieval â€” keeping only the relevant content based on the user's query.\n",
    "\n",
    "#### Query:\n",
    "> \"What is photosynthesis?\"\n",
    "\n",
    "#### Retrieved Document (by a traditional retriever):\n",
    "> \"The Grand Canyon is a famous natural site. Photosynthesis is how plants convert light into energy. Many tourists visit every year.\"\n",
    "\n",
    "*Note: the highlighted part is the relevant content.*\n",
    "\n",
    "#### Problem:\n",
    "- The retriever returns the **entire paragraph**\n",
    "- Only **one sentence** is actually relevant to the query\n",
    "- The rest is **irrelevant noise** that wastes context window and may confuse the LLM\n",
    "\n",
    "#### What Contextual Compression Retriever does:\n",
    "Returns only the relevant part, e.g.:\n",
    "- \"*Photosynthesis is how plants convert light into energy.*\"\n",
    "\n",
    "#### How It Works\n",
    "1. Base Retriever (e.g., FAISS, Chroma) retrieves **N documents**\n",
    "2. A **compressor** (usually an LLM) is applied to each document\n",
    "3. The compressor **keeps only the parts relevant to the query**\n",
    "4. Irrelevant content is **discarded**\n",
    "\n",
    "#### When to Use\n",
    "- Your documents are **long** and contain **mixed information**\n",
    "- You want to **reduce context length** for LLMs\n",
    "- You need to **improve answer accuracy** in RAG pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac949dc6-2692-4f50-82e5-3a4a8762789e",
   "metadata": {},
   "source": [
    "## What is the ContextualCompressionRetriever?\n",
    "\n",
    "The **ContextualCompressionRetriever** is a retriever wrapper in LangChain that combines two key steps:\n",
    "1. **Retrieval:** First, it uses a base retriever (often a vector store retriever) to fetch a set of potentially relevant documents.\n",
    "2. **Compression:** Next, it uses a compressor (such as an LLM, summarizer, or filter) to condense, filter, or summarize the retrieved documentsâ€”returning only the most relevant, concise, and contextually appropriate information to the user or downstream LLM.\n",
    "\n",
    "This approach helps manage context window limitations and improves the quality of information injected into LLM prompts.\n",
    "\n",
    "### Why Use ContextualCompressionRetriever?\n",
    "\n",
    "- **Reduces Noise:** Filters out irrelevant or redundant content from retrieved documents.\n",
    "- **Fits Context Windows:** Compresses and summarizes results to fit within LLM input limits.\n",
    "- **Enhances Relevance:** Ensures that only the most pertinent information is passed to the LLM for answer generation.\n",
    "- **Composable:** You can use different compressors (LLM, keyword, filters, etc.) and combine with any base retriever.\n",
    "\n",
    "### How Does It Work?\n",
    "\n",
    "1. The retriever fetches a batch of candidate documents.\n",
    "2. The compressor (e.g., an LLM or summarizer) processes each candidate, retaining only the most relevant or summarized content.\n",
    "3. The output is a compressed set of documents, maximizing information density and relevance.\n",
    "\n",
    "### Example Usage\n",
    "\n",
    "```python\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# 1. Set up your base retriever (e.g., from a vector store)\n",
    "texts = [\"Doc about LLMs.\", \"Doc about retrievers.\", \"Doc about compressors.\"]\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_texts(texts, embeddings)\n",
    "base_retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 2. Set up a compressor (e.g., LLM-based extractor)\n",
    "llm = OpenAI(temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "# 3. Combine into a ContextualCompressionRetriever\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=base_retriever,\n",
    ")\n",
    "\n",
    "# 4. Retrieve and compress relevant docs\n",
    "results = compression_retriever.get_relevant_documents(\"Explain retrievers in LangChain.\")\n",
    "for doc in results:\n",
    "    print(doc.page_content)\n",
    "```\n",
    "\n",
    "### When to Use ContextualCompressionRetriever\n",
    "\n",
    "- When your raw retrieved documents are too verbose or contain irrelevant information.\n",
    "- If you need to fit more info into a limited context window for LLM prompts.\n",
    "- For improved downstream LLM performance in RAG, summarization, or Q&A tasks.\n",
    "\n",
    "**Summary:**  \n",
    "ContextualCompressionRetriever in LangChain wraps a retriever with a compressor, ensuring that returned results are concise, contextually relevant, and optimized for LLM consumption."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
