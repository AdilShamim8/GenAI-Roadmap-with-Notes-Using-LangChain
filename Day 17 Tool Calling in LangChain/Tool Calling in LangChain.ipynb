{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b72d55c-743b-4115-9c1d-0d1239326568",
   "metadata": {},
   "source": [
    "# Tool Calling in LangChain\n",
    "\n",
    "### What is Tool Calling?\n",
    "\n",
    "**Tool calling** in LangChain enables language models (LLMs) and agents to interact dynamically with external tools, APIs, databases, or retrieval systems during a conversation or workflow. This allows LLMs to take actions, fetch information, perform calculations, or control external systems—making applications more interactive, context-aware, and capable.\n",
    "\n",
    "\n",
    "### How Does Tool Calling Work?\n",
    "\n",
    "1. **Tool Definition:**  \n",
    "   Tools are defined as Python functions, classes, or wrappers around external APIs or services.\n",
    "2. **LLM/Agent Integration:**  \n",
    "   Tools are registered with an agent or LLM in LangChain.\n",
    "3. **Dynamic Invocation:**  \n",
    "   During runtime, the agent (powered by the LLM) decides when and how to call a tool based on the user’s input, and uses the tool’s output in its final response.\n",
    "\n",
    "### Types of Tools\n",
    "\n",
    "- **Retrievers:** Document and data retrievers (vector stores, Wikipedia, SQL, etc.)\n",
    "- **APIs:** Web search, weather, finance, custom APIs.\n",
    "- **Calculators:** Math and logic tools.\n",
    "- **File & Database:** Read/write files, query SQL/NoSQL DBs.\n",
    "- **Custom Tools:** Any callable Python function or class.\n",
    "\n",
    "\n",
    "### Tool Calling with Agents\n",
    "\n",
    "LangChain agents use the LLM’s reasoning capabilities to decide which tools to call and in what order. Tools are described to the LLM so that it knows when they are available and how to use them.\n",
    "\n",
    "\n",
    "### Example: Tool Definition & Agent Tool Calling\n",
    "\n",
    "```python\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"Returns the current UTC time.\"\n",
    "    from datetime import datetime\n",
    "    return datetime.utcnow().isoformat()\n",
    "\n",
    "tools = [get_current_time]\n",
    "```\n",
    "\n",
    "**Registering with an Agent:**\n",
    "\n",
    "```python\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
    ")\n",
    "\n",
    "# Now, the agent can call `get_current_time()` if the user asks for the current time.\n",
    "response = agent.run(\"What is the current time?\")\n",
    "print(response)\n",
    "```\n",
    "\n",
    "\n",
    "### Tool Calling in RAG & Chains\n",
    "\n",
    "- **RAG Workflows:** Tools like retrievers are called to fetch relevant chunks for LLM grounding.\n",
    "- **Chains:** Tools can be invoked as steps in a chain, allowing for multi-step, automated workflows.\n",
    "\n",
    "\n",
    "### Benefits of Tool Calling\n",
    "\n",
    "- **Actionability:** LLMs can take real-world actions, not just generate text.\n",
    "- **Dynamic Information:** Access real-time or external data.\n",
    "- **Composability:** Easily add, remove, or combine tools for complex workflows.\n",
    "\n",
    "**Summary:**  \n",
    "Tool calling in LangChain lets LLMs interact with external systems and APIs, enabling intelligent, actionable, and dynamic applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b12cc2c-afb4-4520-bdad-1a9336643ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26166332-dc5b-4e73-9f05-ea68c18a6c64",
   "metadata": {},
   "source": [
    "## **Tool Binding**\n",
    "\n",
    "- **Tool Binding** is the step where you **register tools** with a **Language Model (LLM)** so that:\n",
    "  1. The LLM knows **what tools are available**\n",
    "  2. It knows **what each tool does** (via description)\n",
    "  3. It knows **what input format to use** (via schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1944c339-03a9-45cf-8768-f3172a95155b",
   "metadata": {},
   "source": [
    "## **Tool Calling**\n",
    "\n",
    "- **Tool Calling** is the process where the **LLM** (language model) decides, during a conversation or task, that it needs to **use a specific tool** (function) — and generates a structured output with:\n",
    "\n",
    "  - the **name of the tool**\n",
    "  - and the **arguments** to call it with\n",
    "\n",
    "- The **LLM does not actually run the tool** — it just suggests the tool and the input arguments. The **actual execution** is handled by **LangChain** or you.\n",
    "  \n",
    "> “What’s 8 multiplied by 7?”\n",
    "\n",
    "The LLM responds with a **tool call**:\n",
    "\n",
    "```json  \n",
    "{  \n",
    "  \"tool\": \"multiply\",  \n",
    "  \"args\": {  \n",
    "    \"a\": 8,  \n",
    "    \"b\": 7  \n",
    "  }  \n",
    "}  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda05529-f128-4ec3-bfc6-55293d971870",
   "metadata": {},
   "source": [
    "## **Tool Execution**\n",
    "\n",
    "- **Tool Execution** is the step where the **actual Python function** (tool) is run using the input arguments that the **LLM suggested during tool calling**.\n",
    "\n",
    "In simpler words:\n",
    "-  The LLM says:  \n",
    "  `\"Hey, call the** multiply** tool with a=8 and b=7.\"`\n",
    "\n",
    "-  **Tool Execution** is when **you or LangChain** actually run:  \n",
    "  `multiply(a=8, b=7)`  \n",
    "\n",
    "- → and get the result: **56**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097a2278-4494-4d64-a84d-bf3f9a904ac1",
   "metadata": {},
   "source": [
    "## **Currency Conversion Too**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510221f0-4840-4513-b40e-6f03cf01ff78",
   "metadata": {},
   "source": [
    "- ❌ **\"LLM, do not try to fill this argument.\"**  \n",
    "- ✅ **\"I (the developer/runtime) will inject this value after running earlier tools.\"**\n",
    "\n",
    "**AI Agent** → **tools/tool calling** (X)\n",
    "\n",
    "---\n",
    "\n",
    "1. User says:  \n",
    "   `\"Convert 10 USD to INR.\"`\n",
    "\n",
    "2. **LLM thinks:**  \n",
    "   `\"I don’t know the rate.\"` First, let me call `get_conversion_factor`.\n",
    "\n",
    "3. **Tool result comes:**  \n",
    "   `85.3415`\n",
    "\n",
    "4. **LLM looks at result, THINKS again:**  \n",
    "   `\"Now I know the rate, next I should call**convert**` with 10 and 85.3415.`\n",
    "\n",
    "5. Tool result comes:  \n",
    "   `853.415 INR`\n",
    "\n",
    "6. **LLM summarizes:**  \n",
    "   *\"10 USD is 853.415 INR at current rate.\"*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
